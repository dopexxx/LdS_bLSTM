{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys,time,os\n",
    "from bLSTM import bLSTM\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibel_retrieve(learn_type):\n",
    "\n",
    "    data = np.load('data/fibel.npz')\n",
    "    phon_dict = np_dict_to_dict(data['phon_dict'])\n",
    "    word_dict = np_dict_to_dict(data['word_dict'])\n",
    "\n",
    "    if learn_type == 'lds':\n",
    "\n",
    "        path = 'data/fibel_alt_targets.npy'\n",
    "        print(\"Loading alternative targets ...\")\n",
    "        alt_targs_raw = np.load(path)\n",
    "\n",
    "\n",
    "        alt_targs = np.array([np.array(d,dtype=np.int8) for d in alt_targs_raw])\n",
    "        print(\"Alternative targets successfully loaded.\")\n",
    "\n",
    "        return ( (data['phons'], data['words']) , (phon_dict, word_dict), alt_targs )\n",
    "    else:\n",
    "        return ( (data['phons'], data['words']) , (phon_dict, word_dict))\n",
    "\n",
    "def np_dict_to_dict(np_dict):\n",
    "    \"\"\"\n",
    "    Converts a dictionary saved via np.save (as structured np array) into an object of type dict\n",
    "\n",
    "    Parameters:\n",
    "    --------------\n",
    "    NP_DICT        : {np.array} structured np.array with dict keys and items\n",
    "\n",
    "    Returns:\n",
    "    --------------\n",
    "    DICT            : {dict} converted NP_DICT\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return {key:np_dict.item().get(key) for key in np_dict.item()}\n",
    "\n",
    "def num_to_str(inputs,logits,labels,alt_targs,dict_in,dict_out,mode='normal'):\n",
    "    \"\"\"\n",
    "    Method receives the numerical arrays and prints the strings\n",
    "\n",
    "    If mode = normal, then alt_targs should be set to [], if it is 'lds' the alternative targets are also printed\n",
    "    \"\"\"\n",
    "\n",
    "    fullPred = logits.argmax(-1) # Prediction string with padding\n",
    "\n",
    "    \n",
    "    #Padded target string\n",
    "    fullTarg = np.copy(labels) \n",
    "    # Set pads to 0 - as preparation for edit_distance\n",
    "\n",
    "    out_str = []\n",
    "    inp_str = []\n",
    "    label_str = []\n",
    "    #print(inputs.shape,fullPred.shape,labels.shape,alt_targs.shape)\n",
    "    #print(dict_in)\n",
    "    #print(dict_out)\n",
    "    #print(inputs[0:5],fullPred[:5],labels[:5])\n",
    "    for k in range(len(fullPred)):\n",
    "        out_str.append(''.join([dict_out[l] if dict_out[l] != '<PAD>' and  dict_out[l] != '<GO>' else '' for l in fullPred[k]]))\n",
    "        inp_str.append(''.join([dict_in[l] if dict_in[l] != '<PAD>' and  dict_in[l] != '<GO>' else '' for l in inputs[k]]))\n",
    "        label_str.append(''.join([dict_out[l] if dict_out[l] != '<PAD>' and  dict_out[l] != '<GO>' else '' for l in labels[k]]))\n",
    "\n",
    "        print(\"The input \" + inp_str[-1].upper() + \" was written as \" + out_str[-1].upper() + \" with the target as \" + label_str[-1].upper())\n",
    "\n",
    "        if mode == 'lds':\n",
    "            alt_targ_str = []\n",
    "\n",
    "            z = np.argwhere(alt_targs[k]==0) # indices of zeros (alt_targs where padded to have equally sized array)\n",
    "            # position 0,1 is the first row that contains zeros (i.e. not an alternative writing anymore)\n",
    "            for l in range(z[0,1]):\n",
    "                alt_targ_str.append(''.join([dict_out[m] if dict_out[m] != '<PAD>' and  dict_out[m] != '<GO>' else '' for m in alt_targs[k,:,l] ]))\n",
    "            print(\"The alternatives were \", alt_targ_str)\n",
    "\n",
    "            \n",
    "def set_model_params(inputs, targets, dict_char2num_x, dict_char2num_y):\n",
    "    \"\"\"\n",
    "    This method can receive data from any dataset (inputs, targets) and the corresponding dictionaries.\n",
    "    It returns the hyperparameters for the model, i.e. input and output sequence length as well as input and output dictionary size.\n",
    "    \"\"\"\n",
    "\n",
    "    # Error handling. If the dicts are not objects of type dict but np.arrays (dicts saved via np.save), convert them back.\n",
    "    if isinstance(dict_char2num_x, np.ndarray):\n",
    "        dict_char2num_x = np_dict_to_dict(dict_char2num_x)\n",
    "    if isinstance(dict_char2num_y, np.ndarray):\n",
    "        dict_char2num_y = np_dict_to_dict(dict_char2num_y)\n",
    "\n",
    "\n",
    "    dict_num2char_x = dict(zip(dict_char2num_x.values(), dict_char2num_x.keys()))\n",
    "    dict_num2char_y = dict(zip(dict_char2num_y.values(), dict_char2num_y.keys()))\n",
    "    x_dict_size = len(dict_char2num_x)\n",
    "    num_classes = len(dict_char2num_y) # (y_dict_size) Cardinality of output dictionary\n",
    "    x_seq_length = len(inputs[0]) - 1 \n",
    "    y_seq_length = len(targets[0]) - 1 # Because of the <GO> as response onset\n",
    "\n",
    "    return x_dict_size, num_classes, x_seq_length, y_seq_length, dict_num2char_x, dict_num2char_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEF (3, 4)\n",
      "(2, 3, 4)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[[ 3  7 12  4]\n",
      " [18 18  2  2]\n",
      " [18  2  2  2]] That was current state\n",
      "(3, 4)\n",
      "(3, 4, 2)\n",
      "(2, 2)\n",
      "YAY!\n",
      "YAY!\n",
      "DONE\n",
      "[[ 3  7 12  1]\n",
      " [18 18  2  2]\n",
      " [18  7  2  2]]\n"
     ]
    }
   ],
   "source": [
    "tf.InteractiveSession()\n",
    "\n",
    "max_alt_wr = 2\n",
    "bs = 3\n",
    "seq_len = 4\n",
    "\n",
    "targ = tf.constant([[3,7,12,4],[18,18,2,2],[18,2,2,2]])\n",
    "\n",
    "wr = tf.constant([[3,7,12,1],[18,18,2,9],[18,7,2,2]],dtype=tf.int8)\n",
    "print('BEF',wr.get_shape())\n",
    "wr = tf.expand_dims(tf.ones([max_alt_wr,1],dtype=tf.int8),1) * wr\n",
    "print(wr.get_shape())\n",
    "wr = tf.transpose(wr,[1,2,0])\n",
    "\n",
    "\n",
    "alt_wr = tf.constant([[[4,7,12,1],[3,7,12,1]],[[1,2,3,4],[1,2,3,3]],\n",
    "                      [[18,7,2,2],[18,9,2,2]]],dtype=tf.int8)\n",
    "alt_wr = tf.transpose(alt_wr,[0,2,1])\n",
    "\n",
    "\n",
    "equal_raw = tf.equal(wr,alt_wr)\n",
    "equal = tf.reduce_all(equal_raw,1)\n",
    "equal_ind = tf.where(equal)\n",
    "\n",
    "\n",
    "a = equal_ind[:,0]\n",
    "print(type(targ),type(alt_wr),type(equal_ind))\n",
    "print(targ.eval(),\"That was current state\")\n",
    "\n",
    "# This is just the creation of the node new_targts.\n",
    "new_targets = tf.py_func(update_tensor,[targ, alt_wr, equal_ind], tf.int8)\n",
    "# This actually executes the new function\n",
    "print(new_targets.eval())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]),)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2,3,4])\n",
    "\n",
    "print(np.where(a==2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "[ 2  9 -4  0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "a = tf.constant([2, 5, -4, 0])\n",
    "aa = tf.Variable(a)\n",
    "print(type(aa))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "b = tf.scatter_update(aa, [1], [9])\n",
    "print(b.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading alternative targets ...\n",
      "Alternative targets successfully loaded.\n",
      "(156, 12) (156, 22) (156, 28, 810)\n"
     ]
    }
   ],
   "source": [
    "((inputs, targets) , (dict_char2num_x, dict_char2num_y), alt_targets) = fibel_retrieve('lds')\n",
    "x_dict_size, num_classes, x_seq_length, y_seq_length, dict_num2char_x, dict_num2char_y = set_model_params(inputs, targets, dict_char2num_x, dict_char2num_y)\n",
    "\n",
    "\n",
    "\n",
    "indices = range(len(inputs))\n",
    "X_train, X_test,Y_train, Y_test, Y_alt_train_l, Y_alt_test_l, ind_train, ind_test = train_test_split(inputs, targets, alt_targets,indices,test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#logp = np.reshape(np.arange(174*22*30),[174,22,30])\n",
    "max_len = max([len(l) for l in Y_alt_train_l])\n",
    "inp_seq_len = len(Y_alt_train_l[1][0])\n",
    "Y_alt_train = np.zeros([len(Y_alt_train_l), inp_seq_len, max_len], dtype=np.int8)\n",
    "for word_ind in range(len(Y_alt_train_l)):\n",
    "    for write_ind in range(len(Y_alt_train_l[word_ind])):\n",
    "        Y_alt_train[word_ind,:,write_ind] = np.array(Y_alt_train_l[word_ind][write_ind],dtype=np.int8)\n",
    "#a=num_to_str(X_train,logp,Y_train,Y_alt_train,dict_num2char_x,dict_num2char_y,'lds')\n",
    "print(X_train.shape, Y_train.shape, Y_alt_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'U',\n",
       " 2: 'l',\n",
       " 3: 'z',\n",
       " 4: 'e',\n",
       " 5: 'p',\n",
       " 6: '|',\n",
       " 7: 'x',\n",
       " 8: 'o',\n",
       " 9: 'i',\n",
       " 10: 'a',\n",
       " 11: 'N',\n",
       " 12: 'E',\n",
       " 13: 'u',\n",
       " 14: 'I',\n",
       " 15: 'd',\n",
       " 16: 'b',\n",
       " 17: 't',\n",
       " 18: 'h',\n",
       " 19: '#',\n",
       " 20: 'm',\n",
       " 21: 'j',\n",
       " 22: '@',\n",
       " 23: ' ',\n",
       " 24: 'r',\n",
       " 25: 'k',\n",
       " 26: '/',\n",
       " 27: '+',\n",
       " 28: 'S',\n",
       " 29: 's',\n",
       " 30: 'n',\n",
       " 31: ':',\n",
       " 32: 'O',\n",
       " 33: 'y',\n",
       " 34: 'g',\n",
       " 35: 'f',\n",
       " 36: 'v',\n",
       " 37: 'Y',\n",
       " 38: '<GO>',\n",
       " 39: '<PAD>'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_num2char_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand how to initialize 2 Tensorflow models,\n",
    "# train them in one session, and save them independently\n",
    "\n",
    "\n",
    "class model(object):\n",
    "    \n",
    "    def __init__(self,size):\n",
    "        \n",
    "        self.inp = tf.placeholder(tf.float32,(size,2),'inp')\n",
    "        self.mat = tf.placeholder(tf.float32,(2,5),'mat')\n",
    "        \n",
    "        \n",
    "        \n",
    "    def foo(self):\n",
    "        self.out = tf.matmul(self.inp,self.mat)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables to save",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-6e3d89be62ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_eager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1325\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No variables to save"
     ]
    }
   ],
   "source": [
    "small = model(3)\n",
    "small.foo()\n",
    "large = model(10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "\n",
    "    \n",
    "    b = sess.run(small.out, feed_dict={small.inp:np.random.random((3,2)),\n",
    "                                      small.mat:np.random.random((2,5))})\n",
    "    print(b)\n",
    "    \n",
    "    saver.save(sess, save_path + '/Model', global_step=epoch, write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_dict_to_dict(np_dict):\n",
    "    \"\"\"\n",
    "    Converts a dictionary saved via np.save (as structured np array) into an object of type dict\n",
    "\n",
    "    Parameters:\n",
    "    --------------\n",
    "    NP_DICT        : {np.array} structured np.array with dict keys and items\n",
    "\n",
    "    Returns:\n",
    "    --------------\n",
    "    DICT            : {dict} converted NP_DICT\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return {key:np_dict.item().get(key) for key in np_dict.item()}\n",
    "\n",
    "\n",
    "\n",
    "def extract_celex(path):\n",
    "    \"\"\"\n",
    "    Reads in data from the CELEX corpus\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    PATH        {str} the path to the desired celex file, i.e. gpl.cd \n",
    "                    (contains orthography and phonology)\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    2 Tuples, each with 2 variables. \n",
    "        First tuple:\n",
    "    W           {np.array} of words (length 51728) for gpl.cd\n",
    "    P           {np.array} of phoneme sequences (length 51728) for gpl.cd\n",
    "        Second tuple:\n",
    "    WORD_DICT   {dict} allowing to map the numerical array W back to strings\n",
    "    PHON_DICT   {dict} doing the same for the phonetical arrays P\n",
    "\n",
    "    \n",
    "    Call via:\n",
    "    path = \"/Users/jannisborn/Desktop/LDS_Data/celex2/german/gpl/gpl.cd\"\n",
    "    ((w,p) , (word_dict, phon_dict)) = extract_celex(path)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "\n",
    "        raw_data = file.read().splitlines()\n",
    "        words = []\n",
    "        phons = []\n",
    "        m = 0\n",
    "        for ind,raw_line in enumerate(raw_data):\n",
    "            \n",
    "            line = raw_line.split(\"\\\\\")\n",
    "\n",
    "            if line[-2]: # Use only words that HAVE a SAMPA transcript (reduces from 51k to 37345)\n",
    "\n",
    "            # exclude foreign words that have the 'æ' tone (SAMPA '{' ) like in PoINte   - 18 words\n",
    "            # exclude foreign words that have the 'ɑ' tone (SAMPA 'A' ) like in NuANce   - 28 words\n",
    "            # exclude foreign words that have a nasal vowel (SAMPA '~' ) like in Jargon  - 22 words\n",
    "                if not 'A' in line[-2] and not '{' in line[-2] and not '~' in line[-2]: \n",
    "\n",
    "                    if not ('tS' in line[-2] and not 'tsch' in line[1]): # exclude 9 foreign words like 'Image', 'Match', 'Punch', 'Sketch'\n",
    "\n",
    "                        if len(line[1]) < 15 and len(line[-2]) < 15 : # exclude extra long words (reduces to 34376)\n",
    "                            \n",
    "                            if len(line[-2]) > m:\n",
    "                                m = len(line[-2])\n",
    "                                print(line[1],line[-2])\n",
    "                                \n",
    "\n",
    "                            words.append(line[1].lower()) # All words are lowercase only\n",
    "                            phons.append(line[-2]) # Using SAMPA notation\n",
    "\n",
    "    return words,phons\n",
    "\n",
    "\n",
    "\n",
    "def str_to_num_dataset(X,Y):\n",
    "    \"\"\"\n",
    "    This method receives 2 lists of strings (input X and output Y) and converts it to padded, numerical arrays.\n",
    "    It returns the numerical dataset as well as the dictionaries to retrieve the strings.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Define dictionaries \n",
    "    # Dictionary assignining a unique integer to each input character\n",
    "    try:\n",
    "        u_characters = set(' '.join(X)) \n",
    "    except TypeError:\n",
    "        # Exception for TIMIT dataset (one phoneme is repr. by seq. of chars)\n",
    "        print(\"TypeError occurred.\")\n",
    "        u_characters = set([quant for seq in X for quant in seq])\n",
    "\n",
    "    char2numX = dict(zip(u_characters, range(1,len(u_characters)+1)))\n",
    "\n",
    "    # Dictionary assignining a unique integer to each phoneme\n",
    "    try:\n",
    "        v_characters = set(' '.join(Y)) \n",
    "    except TypeError:\n",
    "        print(\"TypeError occurred.\")\n",
    "        v_characters = set([quant for seq in Y for quant in seq])\n",
    "    char2numY = dict(zip(v_characters, range(1,len(v_characters)+1))) # Using 0 causes trouble for tf.edit_distance\n",
    "    \n",
    "    # 2. Padding\n",
    "    # Pad inputs\n",
    "    char2numX['<GO>'] = len(char2numX) + 1\n",
    "    char2numX['<PAD>'] = len(char2numX) + 1\n",
    "    mx_l_X = max([len(word) for word in X]) # longest input sequence\n",
    "    # Padd all X for the final form for the LSTM\n",
    "    x = [[char2numX['<GO>']] + [char2numX['<PAD>']]*(mx_l_X - len(word)) +[char2numX[char] for char in word] for word in X]\n",
    "    x = np.array(x) \n",
    "\n",
    "    # Pad targets\n",
    "    char2numY['<GO>'] = len(char2numY) + 1 # Define number denoting the response onset\n",
    "    char2numY['<PAD>'] = len(char2numY) + 1 \n",
    "    mx_l_Y = max([len(phon_seq) for phon_seq in Y]) # longest output sequence\n",
    "\n",
    "    y = [[char2numY['<GO>']] + [char2numY['<PAD>']]*(mx_l_Y - len(ph_sq)) + [char2numY[phon] for phon in ph_sq] for ph_sq in Y]\n",
    "    y = np.array(y)\n",
    "\n",
    "    return ((x,y) , (char2numX,char2numY))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/celex.npz')\n",
    "phon_dict = np_dict_to_dict(data['phon_dict'])\n",
    "word_dict = np_dict_to_dict(data['word_dict'])\n",
    "\n",
    "\n",
    "datao = np.load('data/celex_old.npz')\n",
    "phon_dicto = np_dict_to_dict(datao['phon_dict'])\n",
    "word_dicto = np_dict_to_dict(datao['word_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################## DATA ANALYSIS #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = np.load('/Users/jannisborn/Dropbox/GitHub/LSTM/Models/fibel/normal_run_1/metrics.npz')\n",
    "\n",
    "\n",
    "trainPerf = normal_data['trainPerf']\n",
    "testPerf = normal_data['testPerf']\n",
    "lds_ratio = normal_data['lds_ratio']\n",
    "corr_ratio = normal_data['corr_ratio']\n",
    "lds_loss = normal_data['lds_loss']\n",
    "reg_loss = normal_data['reg_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = np.arange(1001)\n",
    "\n",
    "plt.plot(epochs,lds_ratio)\n",
    "plt.plot(epochs, corr_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
