{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "#import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  30  55  80 105 130 155 180 205 230]\n",
      "[ 50 100 150 200 250 300 350 400 450 500]\n"
     ]
    }
   ],
   "source": [
    "normal_child = np.load('/Users/jannisborn/Dropbox/GitHub/LSTM/Models/childlex/normal_run_13/metrics.npz')\n",
    "lds_child    = np.load('/Users/jannisborn/Dropbox/GitHub/LSTM/Models/childlex/lds_run_12/metrics.npz')\n",
    "normal_fibel = np.load('/Users/jannisborn/Dropbox/GitHub/LSTM/Models/fibel/normal_run_6/metrics.npz')\n",
    "lds_fibel    = np.load('/Users/jannisborn/Dropbox/GitHub/LSTM/Models/fibel/lds_run_6/metrics.npz')\n",
    "\n",
    "epochs = np.arange(500)\n",
    "perf_x = np.arange(250)\n",
    "xticks_e = np.arange(50,501,50)\n",
    "xticks_p = np.arange(5,251,25)\n",
    "xticklabels = xticks_e\n",
    "print(xticks_p)\n",
    "print(xticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Training - Token accuracy plot \n",
    "plt.plot(perf_x,lds_fibel['trainPerf'][:-1,0],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,lds_fibel['trainPerf'][:-1,3],color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,normal_fibel['trainPerf'][:-1,0],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, normal_fibel['trainPerf'][:-1,3],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Fibel dataset - Token accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# Task maybe too easy\n",
    "# LdS: Writing module quickly catches up to regular module. Reading: No difference even during lds time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Training - Word accuracy plot \n",
    "plt.plot(perf_x,lds_fibel['trainPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,lds_fibel['trainPerf'][:-1,4],color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,normal_fibel['trainPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, normal_fibel['trainPerf'][:-1,4],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Fibel dataset - Word accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.5, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# Reading can be solved perfectly\n",
    "# Writing is worse for LdS, but quickly catches up after change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Token accuracy plot \n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,0]),5,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,3]),5,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,0]),5,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,3]),5,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Childlex dataset - Token accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# Reading can be solved perfectly - better than reading - task too easy\n",
    "# Even during LdS regime, Reading is as good as in regular\n",
    "# Writing is wirse but catches up after changing regime\n",
    "\n",
    "# SHOW THIS ONE TOGETHER WITH NEXT ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Word accuracy plot \n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,1]),5,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,4]),5,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,1]),5,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,4]),5,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Childlex dataset - Word accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.5, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# Reading is solved\n",
    "# LdS is initially worse, but then catches up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Testing - Token accuracy plot \n",
    "plt.plot(perf_x,lds_fibel['testPerf'][:-1,0],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,lds_fibel['testPerf'][:-1,3],color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,normal_fibel['testPerf'][:-1,0],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, normal_fibel['testPerf'][:-1,3],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Fibel dataset - Token accuracy - Test data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0, 0.6])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# On test data, writing works better than reading\n",
    "# The LdS agent performs worse on both tasks during the LdS regime\n",
    "# When the LdS agent switches to the regular regime he does not become as good as the unbiased agent. NICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Testing - Word accuracy plot \n",
    "plt.plot(perf_x,lds_fibel['testPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,lds_fibel['testPerf'][:-1,4],color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,normal_fibel['testPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, normal_fibel['testPerf'][:-1,4],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Fibel dataset - Word accuracy - Test data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# NO DATA SAVED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Testing - Token accuracy plot \n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,0]),5,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,2]),5,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['testPerf'][:-1,0]),5,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, savgol_filter(np.squeeze(normal_child['testPerf'][:-1,2]),5,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Childlex dataset - Token accuracy - Test data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0, 0.8])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "\n",
    "# SHOW THIS ONE - Again, LdS model can catch up, here writing is easier than reading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Testing - Word accuracy plot \n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,1]),5,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,3]),5,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['testPerf'][:-1,1]),5,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, savgol_filter(np.squeeze(normal_child['testPerf'][:-1,3]),5,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Childlex dataset - Word accuracy - Test data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(25,color='k')\n",
    "plt.show()\n",
    "\n",
    "# NO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_child['testPerf'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate writing module in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Word ratio accuracy plots\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_child['lds_ratio']),5,1),color='firebrick',linewidth=4,label='LdS model - all spellings')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_child['corr_ratio']),5,1),color='tomato',linewidth=4,label='LdS model - 1 spelling')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_child['lds_ratio']),5,1),color='forestgreen',linewidth=4,label='Reg. model - all spellings')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_child['corr_ratio']),5,1),color='springgreen',linewidth=4,label='Reg. model - 1 spelling')\n",
    "\n",
    "plt.title(\"Childlex dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=5)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()\n",
    "\n",
    "# SHOW THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Training - Word ratio accuracy plots\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['lds_ratio']),5,1),color='firebrick',linewidth=4,label='LdS model - alt. spellings')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['corr_ratio']),5,1),color='tomato',linewidth=4,label='LdS model - single spelling')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['lds_ratio']),5,1),color='forestgreen',linewidth=4,label='Reg. model - alt. spellings')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['corr_ratio']),5,1),color='springgreen',linewidth=4,label='Reg. model - single spellings')\n",
    "\n",
    "plt.title(\"Fibel dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Loss\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_child['lds_loss']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_child['reg_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_child['lds_loss']),5,1),color='forestgreen',linewidth=4,label='Reg. model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_child['reg_loss']),5,1),color='springgreen',linewidth=4,label='Reg. model - regular loss')\n",
    "\n",
    "plt.title(\"Childlex dataset - Loss development\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Training - Loss\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['lds_loss']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['reg_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['lds_loss']),5,1),color='forestgreen',linewidth=4,label='Reg. model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['reg_loss']),5,1),color='springgreen',linewidth=4,label='Reg. model - regular loss')\n",
    "\n",
    "plt.title(\"Fibel dataset - Loss development\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Loss\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_child['read_losses']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "#plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['reg_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_child['read_losses']),5,1),color='forestgreen',linewidth=4,label='Reg. model - lds loss')\n",
    "#plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['reg_loss']),5,1),color='springgreen',linewidth=4,label='Reg. model - regular loss')\n",
    "\n",
    "plt.title(\"Fibel dataset - Loss development\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_pca(n_comp=2, mode='input', plot=True):\n",
    "    \"\"\"\n",
    "    PCA dimensionality reduction of the bLSTM's weight vectors. Plots weight vectors on first 2 eigenvectors.\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    N_COMP \t\t{int} number of PCs to keep. Use 2 if plot=True, can be anything if called from plot_tsne for the sake of preprocessing\n",
    "    MODE \t\t{str} choose from {'input','output'} depending on whether the input or output embedding vectors should be plotted\n",
    "    PLOT \t\t{bool} to decide whether the plots should be displayed and saved (or the pca should just be computed, as preprocessing for tSNE)\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    PCS\t\t\t{np.array} embedding vectors projected at the first 2 pcs. Shape: input_dict_size x 2\n",
    "\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    input_dict = {'t': 1, 'k': 2, 'I': 3, 'j': 4, 'g': 5, 'e': 6, 's': 7, '@': 8, 'E': 9, '#': 10, '|': 11, 'i': 12, 'Y': 13, 'l': 14, 'n': 15, 'f': 16, ':': 17, ' ': 18, 'U': 19, 'd': 20, 'u': 21, 'h': 22, 'S': 23, 'r': 24, 'v': 25, 'y': 26, 'o': 27, '/': 28, 'N': 29, 'p': 30, 'a': 31, 'x': 32, 'O': 33, 'z': 34, '+': 35, 'm': 36, 'b': 37, '<GO>': 38, '<PAD>': 39}\n",
    "    output_dict = {'c': 1, 't': 2, 'k': 3, 'j': 4, 'g': 5, 'e': 6, 's': 7, 'i': 8, 'l': 9, 'n': 10, 'f': 11, 'q': 12, ' ': 13, 'd': 14, 'u': 15, 'w': 16, 'h': 17, 'r': 18, 'v': 19, 'y': 20, 'o': 21, 'p': 22, 'a': 23, 'x': 24, 'z': 25, 'm': 26, 'b': 27, '<GO>': 28, '<PAD>': 29}\n",
    "\n",
    "    inp_rev = dict(zip(input_dict.values(),input_dict.keys()))\n",
    "    out_rev = dict(zip(output_dict.values(), output_dict.keys()))\n",
    "\n",
    "    ide = 499\n",
    "    var = 'writing/encoding_write/enc_embedding'\n",
    "    dic = inp_rev\n",
    "    ling = 'orthografic'\n",
    "    path = '/Users/jannisborn/Dropbox/GitHub/LSTM/Models/childlex/lds_run_12/'\n",
    "    \n",
    "    \"\"\" writing/decoding_write/dec_embedding, reading/encoding_read/enc_embedding, \n",
    "    reading/decoding_read/dec_embedding\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        #saver = tf.train.Saver(tf.global_variables())\n",
    "        #saver.restore(sess,tf.train.latest_checkpoint(self.path))\n",
    "        saver = tf.train.import_meta_graph(path+'my_test_model-'+str(ide)+'.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(path+'./'))\n",
    "\n",
    "        variables_names = [v.name for v in tf.trainable_variables()]\n",
    "        values = sess.run(variables_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for k, v in zip(variables_names, values):\n",
    "            if var in k:\n",
    "            #print(\"Variable: \", k)\n",
    "            #print(\"Shape: \", v.shape)\n",
    "            #print(v)\n",
    "            #print()\n",
    "\n",
    "                weight_vectors = v\n",
    "        print(weight_vectors)\n",
    "\n",
    "        \"\"\"\n",
    "        if mode=='input':\n",
    "        weight_vectors = self.net.input_embedding.eval()\n",
    "        dic = dict(zip(self.input_dict.values(), self.input_dict.keys()))\n",
    "        ling = 'phonetic' if args.task == 'write' else 'orthografic'\n",
    "        elif mode == 'output':\n",
    "        weight_vectors = self.net.output_embedding.eval()\n",
    "        dic = dict(zip(self.output_dict.values(), self.output_dict.keys()))\n",
    "        ling = 'orthografic' if args.task == 'write' else 'phonetic'\n",
    "        else:\n",
    "        raise ValueError(\"Specify mode as either 'input' or 'output'.\" )\n",
    "        \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pcs = pca.fit_transform(weight_vectors)\n",
    "\n",
    "    print(\"The explained variance of the first\", n_comp, 'PCs is (in %):', np.round(100*np.sum(pca.explained_variance_ratio_),3))    \n",
    "\n",
    "\n",
    "    if plot:\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize = (8,8))\n",
    "        ax = fig.add_subplot(1,1,1) \n",
    "        ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "        ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "        ax.set_title(['Projection of the '+ling+' vectors on the first 2 PCs.'], fontsize = 20)\n",
    "        ax.scatter(pcs[:,0], pcs[:,1],s=2)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        print(len(pcs))\n",
    "        for k in range(1,len(pcs)):\n",
    "            # in output dict 0 is not used as key\n",
    "            # will be obsolete after proper retraining\n",
    "            #if mode=='output' and k<28:\n",
    "\n",
    "            ax.annotate(dic[k],(pcs[k,0], pcs[k,1]))  \n",
    "            #else:\n",
    "            #\tax.annotate(dic[k],(pcs[k,0], pcs[k,1]))\n",
    "\n",
    "        plt.savefig(\"PCA_\"+ling+\"_Results.pdf\")\n",
    "\n",
    "        np.save(\"PCA_\"+ling+\"_Results\", pcs)\n",
    "\n",
    "    else:\n",
    "\n",
    "        return pcs\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_tsne(perplexity=10, steps=5000, lr=10, init='random', angle=0.5, mode='input', pca=None):\n",
    "    \"\"\"\n",
    "    t-SNE dimensionality reduction of the bLSTM's weight vectors.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    PERPLEXITY \t{int}, tunable hyperparameter, from [5,50] says author. Higher -> More attention to global aspects of data. \n",
    "                    More samples -> Higher perplexity, perplexity should always < num_samples (default=30)\n",
    "    STEPS \t\t{int}, tunable hyperparameter, amount of iterations, (default=100)\n",
    "    LR \t\t\t{int}, tunable hyperparameter. If too high -> data is circular and equidistant(!) in embedded space. \n",
    "                    If too low -> points compressed in clouds\n",
    "    INIT \t\t{str}, choose from {'random', 'pca'}, the initialization of the embedding space (default=random)\n",
    "    ANGLE \t\t{float}, from [0.0, 1.0], trade-off between accuracy (0.0) and speed (1.0) - default=0.5\n",
    "    MODE \t\t{str} choose from {'input','output'} depending on whether the input or output embedding vectors should be plotted\n",
    "    PCA \t\t{None,int} None per default, if integer is given, data is preprocessed with principal component analysis and \n",
    "                    first PCA PCs are kept.\t\t\n",
    "\n",
    "    About t-SNE:\n",
    "        1)\t\tRepeated runs with the same data and hyperparameters give different results\n",
    "        2)\t\tCluster sizes usually do not mean anything\n",
    "        3) \t\tDistances between clusters may not mean anything\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.manifold import TSNE \n",
    "    \n",
    "    input_dict = {'t': 1, 'k': 2, 'I': 3, 'j': 4, 'g': 5, 'e': 6, 's': 7, '@': 8, 'E': 9, '#': 10, '|': 11, 'i': 12, 'Y': 13, 'l': 14, 'n': 15, 'f': 16, ':': 17, ' ': 18, 'U': 19, 'd': 20, 'u': 21, 'h': 22, 'S': 23, 'r': 24, 'v': 25, 'y': 26, 'o': 27, '/': 28, 'N': 29, 'p': 30, 'a': 31, 'x': 32, 'O': 33, 'z': 34, '+': 35, 'm': 36, 'b': 37, '<GO>': 38, '<PAD>': 39}\n",
    "    output_dict = {'c': 1, 't': 2, 'k': 3, 'j': 4, 'g': 5, 'e': 6, 's': 7, 'i': 8, 'l': 9, 'n': 10, 'f': 11, 'q': 12, ' ': 13, 'd': 14, 'u': 15, 'w': 16, 'h': 17, 'r': 18, 'v': 19, 'y': 20, 'o': 21, 'p': 22, 'a': 23, 'x': 24, 'z': 25, 'm': 26, 'b': 27, '<GO>': 28, '<PAD>': 29}\n",
    "\n",
    "    inp_rev = dict(zip(input_dict.values(),input_dict.keys()))\n",
    "    out_rev = dict(zip(output_dict.values(), output_dict.keys()))\n",
    "\n",
    "    ide = 499\n",
    "    var = 'writing/encoding_write/enc_embedding'\n",
    "    dic = inp_rev\n",
    "    ling = 'orthografic'\n",
    "    path = '/Users/jannisborn/Dropbox/GitHub/LSTM/Models/childlex/lds_run_12/'\n",
    "    \n",
    "    \"\"\" writing/decoding_write/dec_embedding, reading/encoding_read/enc_embedding, \n",
    "    reading/decoding_read/dec_embedding\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        saver = tf.train.import_meta_graph(path+'my_test_model-'+str(ide)+'.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(path+'./'))\n",
    "\n",
    "        variables_names = [v.name for v in tf.trainable_variables()]\n",
    "        values = sess.run(variables_names)\n",
    "        \n",
    "        for k, v in zip(variables_names, values):\n",
    "            if var in k:\n",
    "            #print(\"Variable: \", k)\n",
    "            #print(\"Shape: \", v.shape)\n",
    "            #print(v)\n",
    "\n",
    "               weight_vectors = v\n",
    "\n",
    "\n",
    "        if perplexity >= weight_vectors.shape[0]:\n",
    "            raise ValueError(\"Please make sure the perplexity argument is smaller than the number of data points.\")\n",
    "        \n",
    "\n",
    "\n",
    "        if pca is not None:\n",
    "            # Preprocess via PCA\n",
    "            weight_vectors = plot_pca(n_comp=pca, mode=mode, plot=False)\n",
    "\n",
    "        t = time.time()\n",
    "        tsne = TSNE(n_components=2, verbose=1, perplexity=perplexity, n_iter=steps, learning_rate=lr, init=init, angle=angle)\n",
    "        tsne_results = tsne.fit_transform(weight_vectors)\n",
    "        print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-t))\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize = (8,8))\n",
    "        ax = fig.add_subplot(1,1,1) \n",
    "        ax.set_xlabel('x-tsne', fontsize = 15)\n",
    "        ax.set_ylabel('y-tsne', fontsize = 15)\n",
    "        ax.set_title('tSNE '+ling+' vectors', fontsize = 20)\n",
    "\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "        ax.scatter(tsne_results[:,0], tsne_results[:,1],s=2)\n",
    "        print(tsne_results.shape)\n",
    "        for k in range(1,len(tsne_results)):\n",
    "            # in output dict 0 is not used as key\n",
    "            # will be obsolete after proper retraining\n",
    "                ax.annotate(dic[k],(tsne_results[k,0], tsne_results[k,1]))  \n",
    "\n",
    "        filename = 'tSNE_'+ling+'_perp='+str(perplexity)+'step='+str(steps)+'lr='+str(lr)+'ang='+str(angle)+'init='+init+'pca='+str(pca)\n",
    "\n",
    "        plt.savefig(filename + '.pdf')\n",
    "        np.save(filename, tsne_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_tsne(pca=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
