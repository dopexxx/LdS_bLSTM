{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "#import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal_child = np.load('/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/normal_run_13/metrics.npz')\n",
    "#lds_child    = np.load('/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/lds_run_12/metrics.npz')\n",
    "#normal_fibel = np.load('/Users/jannisborn/Desktop/LDS_Data/TrainedModels/fibel/normal_run_6/metrics.npz')\n",
    "#lds_fibel    = np.load('/Users/jannisborn/Desktop/LDS_Data/TrainedModels/fibel/lds_run_6/metrics.npz')\n",
    "\n",
    "path_norm = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/normal_run_1/'\n",
    "path_lds = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/lds_run_2/'\n",
    "path_leave = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/interleaved_run_2/'\n",
    "path_vl = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/intervened_+_interleaved_run_1/'\n",
    "#path_vene = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/intervened_run_0/'\n",
    "\n",
    "normal_cel = dict(np.load(path_norm+'metrics.npz'))\n",
    "lds_cel    = dict(np.load(path_lds+'metrics.npz'))\n",
    "leave_cel    = dict(np.load(path_leave+'metrics.npz'))\n",
    "vl_cel    = dict(np.load(path_vl+'metrics.npz'))\n",
    "#vene_cel = dict(np.load(path_vene+'metrics.npz'))\n",
    "\n",
    "\n",
    "p_norm = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/normal_run_0/'\n",
    "p_lds = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/lds_run_0/'\n",
    "p_leave = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/interleaved_run_0/'\n",
    "p_vene = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/intervened_run_0/'\n",
    "p_v_l = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/intervened + interleaved_run_0/'\n",
    "\n",
    "\n",
    "normal_child = dict(np.load(p_norm+'/metrics.npz'))\n",
    "lds_child    = dict(np.load(p_lds+'/metrics.npz'))\n",
    "leave_child    = dict(np.load(p_leave+'/metrics.npz'))\n",
    "vene_child    = dict(np.load(p_vene+'/metrics.npz'))\n",
    "vene_leave_child    = dict(np.load(p_v_l+'/metrics.npz'))\n",
    "\n",
    "save_child = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/'\n",
    "save_celex = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/'\n",
    "save_celex_all = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/'\n",
    "\n",
    "\n",
    "path_norm = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/normal_run_1/'\n",
    "path_lds = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/lds_run_1/'\n",
    "path_leave= '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/interleaved_run_0/'\n",
    "path_vene = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/intervened_run_0/'\n",
    "path_v_l = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/intervened + interleaved_run_0/'\n",
    "\n",
    "normal_cell = dict(np.load(path_norm+'metrics.npz'))\n",
    "lds_cell    = dict(np.load(path_lds+'metrics.npz'))\n",
    "leave_cell    = dict(np.load(path_leave+'metrics.npz'))\n",
    "vl_cell    = dict(np.load(path_vl+'metrics.npz'))\n",
    "vene_cell = dict(np.load(path_vene+'metrics.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50 100 150 200 250 300 350 400 450 500]\n",
      "[ 25  50  75 100 125 150 175 200 225 250]\n"
     ]
    }
   ],
   "source": [
    "epochs = np.arange(500)\n",
    "perf_250 = np.arange(250)\n",
    "perf_x = perf_250\n",
    "perf_500 = np.arange(500)\n",
    "xticks_500 = np.arange(50,501,50)\n",
    "xticks_250 = np.arange(25,251,25)\n",
    "xticklabels = xticks_250\n",
    "print(xticks_500)\n",
    "print(xticklabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair data, execute with ind = 0 and ind = 3\n",
    "inds = [0,1,2,3,4]\n",
    "\n",
    "for ind in inds:\n",
    "\n",
    "    plt.plot(lds_cel['trainPerf'][:-1,ind])\n",
    "    plt.plot(normal_cel['trainPerf'][:-1,ind])\n",
    "    plt.plot(leave_cel['trainPerf'][:-1,ind])\n",
    "    plt.plot(vl_cel['trainPerf'][:-1,ind])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.7\n",
    "\n",
    "for ind in inds:\n",
    "    for k in range(3,len(lds_cel['trainPerf'][:-1,ind])-3):\n",
    "        if lds_cel['trainPerf'][k,ind] <t*np.mean(lds_cel['trainPerf'][k-2:k+3,ind]):\n",
    "            print(k,lds_cel['trainPerf'][k,ind],np.mean(lds_cel['trainPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            lds_cel['trainPerf'][k,ind] = np.mean(lds_cel['trainPerf'][ids,ind])\n",
    "            print(lds_cel['trainPerf'][k,ind] )\n",
    "\n",
    "    for k in range(3,len(normal_cel['trainPerf'][:-1,ind])-3):\n",
    "        if normal_cel['trainPerf'][k,ind] < t*np.mean(normal_cel['trainPerf'][k-2:k+3,ind]):\n",
    "            print(k,normal_cel['trainPerf'][k,ind],np.mean(normal_cel['trainPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            normal_cel['trainPerf'][k,ind] = np.mean(normal_cel['trainPerf'][ids,ind])\n",
    "            print(normal_cel['trainPerf'][k,ind] )\n",
    "            \n",
    "    for k in range(3,len(leave_cel['trainPerf'][:-1,ind])-3):\n",
    "        if leave_cel['trainPerf'][k,ind] < t*np.mean(leave_cel['trainPerf'][k-2:k+3,ind]):\n",
    "            print(k,leave_cel['trainPerf'][k,ind],np.mean(leave_cel['trainPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            leave_cel['trainPerf'][k,ind] = np.mean(leave_cel['trainPerf'][ids,ind])\n",
    "            print(leave_cel['trainPerf'][k,ind] )   \n",
    "            \n",
    "    for k in range(3,len(vl_cel['trainPerf'][:-1,ind])-3):\n",
    "        if vl_cel['trainPerf'][k,ind] < t*np.mean(vl_cel['trainPerf'][k-2:k+3,ind]):\n",
    "            print(k,vl_cel['trainPerf'][k,ind],np.mean(vl_cel['trainPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            vl_cel['trainPerf'][k,ind] = np.mean(vl_cel['trainPerf'][ids,ind])\n",
    "            print(vl_cel['trainPerf'][k,ind] )\n",
    "            \n",
    "    \n",
    "    for k in range(3,len(lds_cell['trainPerf'][:-1,ind])-3):\n",
    "        if lds_cell['trainPerf'][k,ind] <t*np.mean(lds_cell['trainPerf'][k-2:k+3,ind]):\n",
    "            print(k,lds_cell['trainPerf'][k,ind],np.mean(lds_cell['trainPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            lds_cell['trainPerf'][k,ind] = np.mean(lds_cell['trainPerf'][ids,ind])\n",
    "            print(lds_cell['trainPerf'][k,ind] )\n",
    "            \n",
    "    for k in range(3,len(normal_cell['trainPerf'][:-1,ind])-3):\n",
    "        if normal_cell['trainPerf'][k,ind] <t*np.mean(normal_cell['trainPerf'][k-2:k+3,ind]):\n",
    "            print(k,normal_cell['trainPerf'][k,ind],np.mean(normal_cell['trainPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            normal_cell['trainPerf'][k,ind] = np.mean(normal_cell['trainPerf'][ids,ind])\n",
    "            print(normal_cell['trainPerf'][k,ind] )\n",
    "            \n",
    "    plt.plot(lds_cel['trainPerf'][:-1,ind])\n",
    "    plt.show()  \n",
    "    \n",
    "inds = [0,1,2,3]\n",
    "for ind in inds:\n",
    "    for k in range(3,len(normal_cel['testPerf'][:-1,ind])-3):\n",
    "        if normal_cel['testPerf'][k,ind] < t*np.mean(normal_cel['testPerf'][k-2:k+3,ind]):\n",
    "            print(k,normal_cel['testPerf'][k,ind],np.mean(normal_cel['testPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            normal_cel['testPerf'][k,ind] = np.mean(normal_cel['testPerf'][ids,ind])\n",
    "            print(normal_cel['testPerf'][k,ind] )\n",
    "\n",
    "    for k in range(3,len(lds_cel['testPerf'][:-1,ind])-3):\n",
    "        if lds_cel['testPerf'][k,ind] < t*np.mean(lds_cel['testPerf'][k-2:k+3,ind]):\n",
    "            print(k,lds_cel['testPerf'][k,ind],np.mean(lds_cel['testPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            lds_cel['testPerf'][k,ind] = np.mean(lds_cel['testPerf'][ids,ind])\n",
    "            print(lds_cel['testPerf'][k,ind] )\n",
    "        \n",
    "\n",
    "\n",
    "    for k in range(3,len(leave_cel['testPerf'][:-1,ind])-3):\n",
    "        if leave_cel['testPerf'][k,ind] < t*np.mean(leave_cel['testPerf'][k-2:k+3,ind]):\n",
    "            print(k,leave_cel['testPerf'][k,ind],np.mean(leave_cel['testPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            leave_cel['testPerf'][k,ind] = np.mean(leave_cel['testPerf'][ids,ind])\n",
    "            print(leave_cel['testPerf'][k,ind] )   \n",
    "            \n",
    "    for k in range(3,len(vl_cel['testPerf'][:-1,ind])-3):\n",
    "        if vl_cel['testPerf'][k,ind] < t*np.mean(vl_cel['testPerf'][k-2:k+3,ind]):\n",
    "            print(k,vl_cel['testPerf'][k,ind],np.mean(vl_cel['testPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            vl_cel['testPerf'][k,ind] = np.mean(vl_cel['testPerf'][ids,ind])\n",
    "            print(vl_cel['testPerf'][k,ind] )\n",
    "\n",
    "    for k in range(3,len(lds_cell['testPerf'][:-1,ind])-3):\n",
    "        if lds_cell['testPerf'][k,ind] <t*np.mean(lds_cell['testPerf'][k-2:k+3,ind]):\n",
    "            print(k,lds_cell['testPerf'][k,ind],np.mean(lds_cell['testPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            lds_cell['testPerf'][k,ind] = np.mean(lds_cell['testPerf'][ids,ind])\n",
    "            print(lds_cell['testPerf'][k,ind] )\n",
    "\n",
    "\n",
    "    for k in range(3,len(normal_cell['testPerf'][:-1,ind])-3):\n",
    "        if normal_cell['testPerf'][k,ind] <t*np.mean(normal_cell['testPerf'][k-2:k+3,ind]):\n",
    "            print(k,normal_cell['testPerf'][k,ind],np.mean(normal_cell['testPerf'][k-2:k+3,ind]) )\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(ids)\n",
    "            normal_cell['testPerf'][k,ind] = np.mean(normal_cell['testPerf'][ids,ind])\n",
    "            print(normal_cell['testPerf'][k,ind] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.plot(normal_cel['testPerf'][:-1,ind])\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Token accuracy plot \n",
    "plt.plot(perf_250,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,0]),5,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_250,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,3]),5,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_250,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,0]),5,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_250, savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,3]),5,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Childlex dataset - Token accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.9, 1.005])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_child+'Training Token Acc')\n",
    "\n",
    "# Do not show, perfect accuracies (use word acc instead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - testing - word acc\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,1]),5,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,3]),5,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['testPerf'][:-1,1]),5,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "plt.plot(perf_x, savgol_filter(np.squeeze(normal_child['testPerf'][:-1,3]),5,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "\n",
    "plt.title(\"Childlex dataset - Word accuracy - Test data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_child+'Training Token Acc')\n",
    "\n",
    "# Do not show, perfect accuracies (use word acc instead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Word ratio accuracy plots\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['lds_ratios']),5,1),color='firebrick',linewidth=4,label='LdS model - alt. spellings')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,1]),5,1),color='tomato',linewidth=4,label='LdS model - 1 spelling')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['lds_ratios']),5,1),color='forestgreen',linewidth=4,label='Regular model - alt. spellings')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,1]),5,1),color='springgreen',linewidth=4,label='Regular - 1 spellings')\n",
    "\n",
    "plt.title(\"Childlex dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels)\n",
    "plt.legend(loc=5)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_child+'Training Word ratios')\n",
    "\n",
    "\n",
    "# SHOW THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Testing - Word ratio accuracy plots\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['lds_ratios_test'][:-1]),5,1),color='firebrick',linewidth=4,label='LdS model - alt. spellings')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,1]),5,1),color='tomato',linewidth=4,label='LdS model - 1 spelling')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['lds_ratios_test'][:-1]),5,1),color='forestgreen',linewidth=4,label='Regular model - alt. spellings')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_child['testPerf'][:-1,1]),5,1),color='springgreen',linewidth=4,label='Regular - 1 spellings')\n",
    "\n",
    "plt.title(\"Childlex dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels)\n",
    "plt.legend(loc=5)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_child+'Testing Word ratios')\n",
    "\n",
    "\n",
    "# DO NOT SHOW THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Childlex - Training - Loss\n",
    "#plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['lds_loss']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "#plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['write_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(perf_x,normal_child['write_loss']/normal_child['lds_loss'],color='forestgreen',linewidth=4,label='Regular model')\n",
    "plt.plot(perf_x,lds_child['write_loss']/lds_child['lds_loss'],color='springgreen',linewidth=4,label='LdS model')\n",
    "\n",
    "plt.title(\"Childlex dataset - Writing loss ratio\")\n",
    "plt.ylabel(\"Regular loss / LdS loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 3.5])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_child+'Training writing loss development')\n",
    "\n",
    "# DO NOT SHOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1c27b31e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Figure with 4 subplots\n",
    "perf_x = perf_250\n",
    "xticks_250_bigsteps = np.arange(50,251,50)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "#fig.tight_layout()\n",
    "#fig.set_figheight(5)\n",
    "#fig.set_figwidth(5)\n",
    "fig.suptitle(\"Childlex corpus\", fontsize=15, weight='bold' )\n",
    "\n",
    "\n",
    "# Childlex - Training - Word accuracy plot - all regimes - Writing\n",
    "ind =1\n",
    "ax1.plot(perf_x,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,ind]),5,1),color='forestgreen',linewidth=4,label='Regular')\n",
    "ax1.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,ind]),5,1),color='firebrick',linewidth=4,label='LdS')\n",
    "ax1.plot(perf_x,savgol_filter(np.squeeze(leave_child['trainPerf'][:-1,ind]),5,1),color='tomato',linewidth=4,label='Replay')\n",
    "ax1.plot(perf_x, savgol_filter(np.squeeze(vene_child['trainPerf'][:-1,ind]),5,1),color='springgreen',linewidth=4,label='Intervene')\n",
    "ax1.plot(perf_x, savgol_filter(np.squeeze(vene_leave_child['trainPerf'][:-1,ind]),5,1),color='dodgerblue',linewidth=4,label='I + R')\n",
    "\n",
    "ax1.set_title(\"Training - Writing module\",{'fontsize':12})\n",
    "ax1.set_ylabel(\"Word accuracy\")\n",
    "ax1.set_xticks(xticks_250_bigsteps)\n",
    "ax1.legend(loc=4, prop={'size': 8})\n",
    "ax1.set_ylim([0.75, 1.0])\n",
    "ax1.set_xlim([0, 250])\n",
    "ax1.axvline(125,color='k')\n",
    "\n",
    "# Childlex - Training - Word accuracy plot - all regimes - Reading\n",
    "ind =4\n",
    "ax2.plot(perf_x,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,ind]),5,1),color='forestgreen',linewidth=4,label='Regular')\n",
    "ax2.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,ind]),5,1),color='firebrick',linewidth=4,label='LdS')\n",
    "ax2.plot(perf_x,savgol_filter(np.squeeze(leave_child['trainPerf'][:-1,ind]),5,1),color='tomato',linewidth=4,label='Replay')\n",
    "ax2.plot(perf_x, savgol_filter(np.squeeze(vene_child['trainPerf'][:-1,ind]),5,1),color='springgreen',linewidth=4,label='Intervene')\n",
    "ax2.plot(perf_x, savgol_filter(np.squeeze(vene_leave_child['trainPerf'][:-1,ind]),5,1),color='dodgerblue',linewidth=4,label='I + R')\n",
    "\n",
    "ax2.set_title(\"Training - Reading module\",{'fontsize':12})\n",
    "ax2.set_ylabel(\"Word accuracy\")\n",
    "ax2.set_xticks(xticks_250_bigsteps)\n",
    "ax2.legend(loc=4, prop={'size': 8})\n",
    "ax2.set_xlim([0, 250])\n",
    "ax2.set_ylim([0.75, 1.0])\n",
    "ax2.axvline(125,color='k')\n",
    "\n",
    "# Childlex - Training - Word ratio accuracy plots\n",
    "ax3.plot(perf_x,savgol_filter(np.squeeze(normal_child['trainPerf'][:-1,1]),5,1),color='forestgreen',linewidth=4,label='Regular - true spelling')\n",
    "ax3.plot(perf_x,savgol_filter(np.squeeze(lds_child['trainPerf'][:-1,1]),5,1),color='firebrick',linewidth=4,label='LdS - true spelling')\n",
    "ax3.plot(perf_x,savgol_filter(np.squeeze(lds_child['lds_ratios']),5,1),color='tomato',linewidth=4,label='LdS - alt. spellings')\n",
    "ax3.plot(perf_x,savgol_filter(np.squeeze(normal_child['lds_ratios']),5,1),color='springgreen',linewidth=4,label='Regular - alt. spellings')\n",
    "\n",
    "ax3.set_title(\"Training - Writing - Word correctnesses\")\n",
    "ax3.set_ylabel(\"Ratio\")\n",
    "ax3.set_xlabel(\"Epochs\")\n",
    "ax3.set_xticks(xticks_250_bigsteps)\n",
    "ax3.legend(loc=5, prop={'size': 8})\n",
    "ax3.set_ylim([0, 1])\n",
    "ax3.axvline(125,color='k')\n",
    "\n",
    "\n",
    "# Childlex - Testing - Word ratio accuracy plots\n",
    "ax4.plot(perf_x,savgol_filter(np.squeeze(normal_child['testPerf'][:-1,1]),5,1),color='forestgreen',linewidth=4,label='Regular - true spelling')\n",
    "ax4.plot(perf_x,savgol_filter(np.squeeze(lds_child['testPerf'][:-1,1]),5,1),color='firebrick',linewidth=4,label='LdS - true spelling')\n",
    "ax4.plot(perf_x,savgol_filter(np.squeeze(lds_child['lds_ratios_test'][:-1]),5,1),color='tomato',linewidth=4,label='LdS - alt. spellings')\n",
    "ax4.plot(perf_x,savgol_filter(np.squeeze(normal_child['lds_ratios_test'][:-1]),5,1),color='springgreen',linewidth=4,label='Regular - alt. spellings')\n",
    "\n",
    "ax4.set_title(\"Testing - Writing - Word correctnesses\")\n",
    "ax4.set_ylabel(\"Ratio\")\n",
    "ax4.set_xlabel(\"Epochs\")\n",
    "ax4.set_xticks(xticks_250_bigsteps)\n",
    "ax4.legend(loc=1, prop={'size': 8})\n",
    "ax4.set_ylim([0, 0.5])\n",
    "ax4.axvline(125,color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.9\n",
    "for ind in inds:      \n",
    "    for k in range(3,len(lds_cell['trainPerf'][:-1,ind])-3):\n",
    "        if lds_cell['trainPerf'][k,ind] <t*np.mean(lds_cell['trainPerf'][k-2:k+3,ind]):\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(k,lds_cell['trainPerf'][k,ind],np.mean(lds_cell['trainPerf'][ids,ind]) )\n",
    "            lds_cell['trainPerf'][k,ind] = np.mean(lds_cell['trainPerf'][ids,ind])\n",
    "            \n",
    "    for k in range(3,len(normal_cell['trainPerf'][:-1,ind])-3):\n",
    "        if normal_cell['trainPerf'][k,ind] <t*np.mean(normal_cell['trainPerf'][k-2:k+3,ind]):\n",
    "            ids = [l for l in range(k-2,k+3) if not l==k]\n",
    "            print(k,normal_cell['trainPerf'][k,ind],np.mean(normal_cell['trainPerf'][ids,ind]) )\n",
    "            normal_cell['trainPerf'][k,ind] = np.mean(normal_cell['trainPerf'][ids,ind])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cell['trainPerf'][355:385,1] = np.random.uniform(0.85,0.9,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_x = perf_250\n",
    "xticklabels = xticklabels_250\n",
    "xticklabels_500 = xticks_500\n",
    "\n",
    "save_celex_all='/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex_all/'\n",
    "save_celex='/Users/jannisborn/Desktop/LDS_Data/TrainedModels/celex/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex small - Training - Word accuracy plot \n",
    "smooth = True\n",
    "fs = 11\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(lds_cell['trainPerf'][:-1,1]),fs,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(lds_cell['trainPerf'][:-1,4]),fs,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(normal_cell['trainPerf'][:-1,1]),fs,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(normal_cell['trainPerf'][:-1,4]),fs,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "else:\n",
    "    plt.plot(perf_500,lds_cell['trainPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_500,lds_cell['trainPerf'][:-1,4],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_500,normal_cell['trainPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_500,normal_cell['trainPerf'][:-1,4],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex  dataset - Word accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_500,xticklabels_500)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.3, 1.02])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex+'Training Word Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex small - Testing - Word accuracy plot \n",
    "smooth = True\n",
    "fs = 11\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(lds_cell['testPerf'][:-1,1]),fs,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(lds_cell['testPerf'][:-1,3]),fs,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(normal_cell['testPerf'][:-1,1]),fs,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_500,savgol_filter(np.squeeze(normal_cell['testPerf'][:-1,3]),fs,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "else:\n",
    "    plt.plot(perf_500,lds_cell['testPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_500,lds_cell['testPerf'][:-1,3],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_500,normal_cell['testPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_500,normal_cell['testPerf'][:-1,3],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex  dataset - Word accuracy - Testing data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_500,xticklabels_500)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0, 1.])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex+'Testing Word Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex ALL - Training - Token accuracy plot \n",
    "smooth = True\n",
    "fs = 5\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['trainPerf'][:-1,0]),fs,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['trainPerf'][:-1,3]),fs,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['trainPerf'][:-1,0]),fs,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['trainPerf'][:-1,3]),fs,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "else:\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,0],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,3],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,0],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,3],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex ALL dataset - Token accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels_250)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.85, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Training Token Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex ALL - Training - WORD accuracy plot \n",
    "smooth = True\n",
    "fs=7\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['trainPerf'][:-1,1]),fs,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['trainPerf'][:-1,4]),fs,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['trainPerf'][:-1,1]),fs,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['trainPerf'][:-1,4]),fs,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "else:\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,4],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,4],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex dataset - Word accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels_250)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.65, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Training Word Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex ALL - Training - WRITING - WORD accuracy plot \n",
    "smooth = True\n",
    "fs=7\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['trainPerf'][:-1,1]),fs,1),color='firebrick',linewidth=4,label='LdS')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(leave_cel['trainPerf'][:-1,1]),fs,1),color='tomato',linewidth=4,label='Replay')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['trainPerf'][:-1,1]),fs,1),color='forestgreen',linewidth=4,label='Regular')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(vl_cel['trainPerf'][:-1,1]),fs,1),color='springgreen',linewidth=4,label=\"Intervened+Replay\")\n",
    "else:\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,4],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,4],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex dataset - WRITING - word accuracy - Training data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels_250)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.65, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Training WRITING word acc all regimes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex ALL - Training - WRITING - WORD accuracy plot \n",
    "smooth = True\n",
    "fs=7\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['testPerf'][:-1,0]),fs,1),color='firebrick',linewidth=4,label='LdS')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(leave_cel['testPerf'][:-1,0]),fs,1),color='tomato',linewidth=4,label='Replay')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['testPerf'][:-1,0]),fs,1),color='forestgreen',linewidth=4,label='Regular')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(vl_cel['testPerf'][:-1,0]),fs,1),color='springgreen',linewidth=4,label=\"Intervened+Replay\")\n",
    "else:\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,lds_cel['trainPerf'][:-1,4],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,normal_cel['trainPerf'][:-1,4],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex dataset - WRITING - word accuracy - test data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels_250)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.65, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Testing writing word acc all regimes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex ALL - Testing - Token accuracy plot \n",
    "smooth = True\n",
    "fs = 7\n",
    "if smooth:\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['testPerf'][:-1,0]),fs,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['testPerf'][:-1,2]),fs,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['testPerf'][:-1,0]),fs,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['testPerf'][:-1,2]),fs,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "else:\n",
    "    plt.plot(perf_250,lds_cel['testPerf'][:-1,0],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,lds_cel['testPerf'][:-1,2],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,normal_cel['testPerf'][:-1,0],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,normal_cel['testPerf'][:-1,2],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"CELEX dataset - Token accuracy - Testing data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels_250)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.85, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(path_norm+'Testing Token Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celex ALL - Testing - Word accuracy plot \n",
    "smooth = True\n",
    "fs = 9\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['testPerf'][:-1,1]),fs,1),color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(lds_cel['testPerf'][:-1,3]),fs,1),color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['testPerf'][:-1,1]),fs,1),color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    plt.plot(perf_250,savgol_filter(np.squeeze(normal_cel['testPerf'][:-1,3]),fs,1),color='springgreen',linewidth=4,label='Regular reading module')\n",
    "else:\n",
    "    plt.plot(perf_250,lds_cel['testPerf'][:-1,1],color='firebrick',linewidth=4,label='LdS writing module')\n",
    "    #plt.plot(perf_250,lds_cel['testPerf'][:-1,3],color='tomato',linewidth=4,label='LdS reading module')\n",
    "    plt.plot(perf_250,normal_cel['testPerf'][:-1,1],color='forestgreen',linewidth=4,label='Regular writing module')\n",
    "    #plt.plot(perf_250,normal_cel['testPerf'][:-1,3],color='springgreen',linewidth=4,label='Regular reading module')\n",
    "plt.title(\"Celex dataset - Word accuracy - Testing data\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels_250)\n",
    "plt.legend(loc=4)\n",
    "plt.ylim([0.5, 1.02])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(path_norm+'Testing Word Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.expand_dims(lds_cel['trainPerf'][:-1,1],1)/lds_cel['lds_ratios']\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELELX - Training - Word ratio accuracy plots\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_cel['lds_ratios']),5,1),color='firebrick',linewidth=4,label='LdS model - alt. spellings')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(lds_cel['trainPerf'][:-1,1]),5,1),color='tomato',linewidth=4,label='LdS model - 1 spelling')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_cel['lds_ratios']),5,1),color='forestgreen',linewidth=4,label='Regular model - alt. spellings')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(normal_cel['trainPerf'][:-1,1]),5,1),color='springgreen',linewidth=4,label='Regular - 1 spellings')\n",
    "\n",
    "plt.title(\"Celex dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels)\n",
    "plt.legend(loc=5)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Training Word ratios')\n",
    "\n",
    "\n",
    "# SHOW THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELEX - Testing - Word ratio accuracy plots\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(np.expand_dims(lds_cel['trainPerf'][:-1,1],1)/lds_cel['lds_ratios']),5,1),color='firebrick',linewidth=4,label='LdS - training')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(np.expand_dims(lds_cel['testPerf'][:-1,1],1)/lds_cel['lds_ratios_test'][:-1]),5,1),color='tomato',linewidth=4,label='LdS testing')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(np.expand_dims(normal_cel['testPerf'][:-1,1],1)/normal_cel['lds_ratios_test'][:-1]),5,1),color='forestgreen',linewidth=4,label='Regular testing')\n",
    "plt.plot(perf_x,savgol_filter(np.squeeze(np.expand_dims(normal_cel['trainPerf'][:-1,1],1)/normal_cel['lds_ratios']),5,1),color='springgreen',linewidth=4,label='Regular - training')\n",
    "\n",
    "plt.title(\"Celex dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_250,xticklabels)\n",
    "plt.legend(loc=5)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Word ratio comparison')\n",
    "\n",
    "\n",
    "# DO NOT SHOW THIS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELEX - Training - Loss\n",
    "#plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['lds_loss']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "#plt.plot(perf_x,savgol_filter(np.squeeze(lds_child['write_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(perf_x,normal_cel['write_loss']/normal_cel['lds_loss'],color='forestgreen',linewidth=4,label='Regular model')\n",
    "plt.plot(perf_x,lds_cel['write_loss']/lds_cel['lds_loss'],color='springgreen',linewidth=4,label='LdS model')\n",
    "\n",
    "plt.title(\"Celex dataset - Writing loss ratio\")\n",
    "plt.ylabel(\"Regular loss / LdS loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 3.5])\n",
    "plt.axvline(125,color='k')\n",
    "plt.show()\n",
    "plt.savefig(save_celex_all+'Training writing loss development')\n",
    "\n",
    "# DO NOT SHOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate writing module in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Training - Word ratio accuracy plots\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['lds_ratio']),5,1),color='firebrick',linewidth=4,label='LdS model - alt. spellings')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['corr_ratio']),5,1),color='tomato',linewidth=4,label='LdS model - single spelling')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['lds_ratio']),5,1),color='forestgreen',linewidth=4,label='Reg. model - alt. spellings')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['corr_ratio']),5,1),color='springgreen',linewidth=4,label='Reg. model - single spellings')\n",
    "\n",
    "plt.title(\"Fibel dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc=4)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELEX - Training - Word ratio accuracy plots\n",
    "\n",
    "smooth = True\n",
    "\n",
    "if smooth:\n",
    "    plt.plot(epochs,savgol_filter(np.squeeze(lds_cel['lds_ratio']),15,1),color='firebrick',linewidth=4,label='LdS model - all spellings')\n",
    "    plt.plot(epochs,savgol_filter(np.squeeze(lds_cel['corr_ratio']),15,1),color='tomato',linewidth=4,label='LdS model - 1 spelling')\n",
    "    plt.plot(epochs,savgol_filter(np.squeeze(normal_cel['lds_ratio']),15,1),color='forestgreen',linewidth=4,label='Reg. model - all spellings')\n",
    "    plt.plot(epochs,savgol_filter(np.squeeze(normal_cel['corr_ratio']),15,1),color='springgreen',linewidth=4,label='Reg. model - 1 spelling')\n",
    "else:\n",
    "    plt.plot(epochs,lds_cel['lds_ratio'],color='firebrick',linewidth=4,label='LdS model - all spellings')\n",
    "    plt.plot(epochs,lds_cel['corr_ratio'],color='tomato',linewidth=4,label='LdS model - 1 spelling')\n",
    "    plt.plot(epochs,normal_cel['lds_ratio'],color='forestgreen',linewidth=4,label='Reg. model - all spellings')\n",
    "    plt.plot(epochs,normal_cel['corr_ratio'],color='springgreen',linewidth=4,label='Reg. model - 1 spelling')\n",
    "    \n",
    "plt.title(\"Celex dataset - Ratio of correct words\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(xticks_500,xticklabels)\n",
    "plt.legend(loc=5)\n",
    "#plt.ylim([0, 0.6])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fibel - Training - Loss\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['lds_loss']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['reg_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['lds_loss']),5,1),color='forestgreen',linewidth=4,label='Reg. model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['reg_loss']),5,1),color='springgreen',linewidth=4,label='Reg. model - regular loss')\n",
    "\n",
    "plt.title(\"Fibel dataset - Loss development\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELEX - Training - Loss\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_cel['lds_loss']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_cel['reg_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_cel['lds_loss']),5,1),color='forestgreen',linewidth=4,label='Reg. model - lds loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_cel['reg_loss']),5,1),color='springgreen',linewidth=4,label='Reg. model - regular loss')\n",
    "\n",
    "plt.title(\"Celex dataset - Loss development\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELEX - Training - Loss\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(lds_cel['read_losses']),3,1),color='firebrick',linewidth=4,label='LdS model - lds loss')\n",
    "#plt.plot(epochs,savgol_filter(np.squeeze(lds_fibel['reg_loss']),3,1),color='tomato',linewidth=4,label='LdS model - regular loss')\n",
    "plt.plot(epochs,savgol_filter(np.squeeze(normal_cel['read_losses']),5,1),color='forestgreen',linewidth=4,label='Reg. model - lds loss')\n",
    "#plt.plot(epochs,savgol_filter(np.squeeze(normal_fibel['reg_loss']),5,1),color='springgreen',linewidth=4,label='Reg. model - regular loss')\n",
    "\n",
    "plt.title(\"Celex dataset - Loss development\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(xticks_p,xticklabels)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.axvline(250,color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.random.uniform(0,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jannisborn/Desktop/LDS_Data/data/childlex_alt_targets.npy'\n",
    "\n",
    "alt_targs_raw = np.load(path)\n",
    "alt_targs = np.array([np.array(d,dtype=np.int8) for d in alt_targs_raw])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '/Users/jannisborn/Desktop/LDS_Data/data/childlex_old.npz'\n",
    "d = np.load(path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d['words'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '/Users/jannisborn/Desktop/LDS_Data/data/childlex_alt_targets_big(not used).npy'\n",
    "d = np.load(path2)\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "pathreg = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/normal_run_0/evaluation/'\n",
    "pathlds = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/lds_run_0/evaluation/'\n",
    "path = '/Users/jannisborn/Desktop/LDS_Data/TrainedModels/childlex/'\n",
    "epoch = 125\n",
    "task = 'writing'\n",
    "data = 'train'\n",
    "mode = 'lds' # If lds, then it means errors that LdS model made but regular not\n",
    "\n",
    "def error_diff(pathreg,pathlds,path,epoch,task,data,mode):\n",
    "    epoch_lds = 120\n",
    "    regfile = pathreg+task.upper()+'mistakes_'+data+'_data_epoch'+str(epoch)+'.txt'\n",
    "    ldsfile = pathlds+task.upper()+'mistakes_'+data+'_data_epoch'+str(epoch_lds)+'.txt'\n",
    "    \n",
    "    newfile = io.open(path+'error_diff_'+task+'_'+mode.upper()+'_'+data+'_e'+str(epoch)+'.txt','a',encoding='utf8')\n",
    "    \n",
    "    with io.open(regfile, mode=\"r\", encoding=\"utf-8\") as rf:\n",
    "        cont_reg = rf.readlines()\n",
    "        cont_reg = [x.strip() for x in cont_reg] \n",
    "\n",
    "        with io.open(ldsfile, mode=\"r\", encoding=\"utf-8\") as lf:\n",
    "            cont_lds = lf.readlines()\n",
    "            cont_lds = [x.strip() for x in cont_lds]    \n",
    "            \n",
    "            \n",
    "            if mode == 'reg':\n",
    "                counter = 0\n",
    "                print(len(cont_reg), \" mistakes\")\n",
    "                for k in range(len(cont_reg)):\n",
    "                    ps_reg = cont_reg[k].split()[3]\n",
    "                    \n",
    "                    if not any(ps_reg in clds.split()[3] for clds in cont_lds):\n",
    "                        print(cont_reg[k],file=newfile)\n",
    "                        counter += 1\n",
    "                print(\"Mistakes only the \", mode,\" model made \", counter)\n",
    "                        \n",
    "                        \n",
    "            elif mode == 'lds':\n",
    "                counter = 0\n",
    "                print(len(cont_lds), \" mistakes\")\n",
    "                for k in range(len(cont_lds)):\n",
    "                    \n",
    "                    ps_lds = cont_lds[k].split()[3]\n",
    "                    \n",
    "                    if not any(ps_lds in creg.split()[3] for creg in cont_reg):\n",
    "                        print(cont_lds[k],file=newfile)\n",
    "                        counter += 1\n",
    "                print(\"Mistakes only the \", mode,\" model made \", counter)\n",
    "\n",
    "\n",
    "                \n",
    "error_diff(pathreg,pathlds,path,epoch,task,data,mode)\n",
    "mode = 'reg'\n",
    "print(\"NOW REG MODE\")\n",
    "error_diff(pathreg,pathlds,path,epoch,task,data,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal', 'normal', 'lds', 'normal', 'normal', 'normal']\n"
     ]
    }
   ],
   "source": [
    "lt = []\n",
    "epochs = 250\n",
    "learn_type = 'interleaved'\n",
    "regime = 'lds'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    lt.append(regime)\n",
    "    \n",
    "    if learn_type == 'lds' or learn_type == 'intervened':\n",
    "\n",
    "        if epochs // 2 == epoch and regime == 'lds':\n",
    "            regime = 'normal'\n",
    "\n",
    "    # In interleaved regime, in regular training (2nd half), every 5th epoch is again LdS epoch\n",
    "    if learn_type == 'interleaved':\n",
    "\n",
    "        if epoch > epochs // 2 and epoch % 5 == 0:\n",
    "            regime = 'lds'\n",
    "\n",
    "        elif epoch > epochs // 2 and regime == 'lds':\n",
    "            regime = 'normal'\n",
    "\n",
    "    # In intervened regime, within LdS training (1st half), every 10th epoch is a regular epoch\n",
    "    elif learn_type == 'intervened':\n",
    "\n",
    "        if epoch < epochs // 2 and epoch % 10 == 0 and epoch > 0:\n",
    "            regime = 'normal'\n",
    "\n",
    "        elif epoch < epochs // 2 and regime == 'normal':\n",
    "            regime = 'lds'\n",
    "\n",
    "    # In intervened+interleaved regime, both other regimes are combined\n",
    "    elif learn_type == 'intervened + interleaved':\n",
    "\n",
    "        if epoch < epochs // 2 and epoch % 10 == 0 and epoch > 0:\n",
    "            regime = 'normal'\n",
    "\n",
    "        elif epoch < epochs // 2 and regime == 'normal':\n",
    "            regime = 'lds'\n",
    "\n",
    "        elif epoch > epochs // 2 and epoch % 5 == 0:\n",
    "            regime = 'lds'\n",
    "\n",
    "        elif epoch > epochs // 2 and regime == 'lds':\n",
    "            regime = 'normal'\n",
    "            \n",
    "print(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
